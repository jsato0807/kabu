kabu_montecarlo.pyが終わったら、kabu_backtest.pyを、cumulativeなreturnをtxtfileに保存するように修正して、再度kabu_montecarlo.pyを実行せよ
svmとGAの論文を読んで、完全に再現
svmとGAの論文で使われている、動的なGAについて、ハイパーパラメータをどう決めるか、その動的な手法が高精度なのはどのような原因が考えられるか解読する
svmとGAの論文以外にcitationの多い、overfitしていない先行研究を探す→Modeling, forecasting and trading the EUR exchange rates with hybrid rolling genetic algorithms-Support vector regression forecast combinations（citation132）
kabu_montecarlo.pyはパラメータを全て一様分布から生成しているが、これも先行研究を探す
covariance penalitesの論文にある、CV以外の先行研究となった手法を調べる
cpcvを日足より短い”大量の”データを使って再度試す
うまくいきそうなら、その結果に対してcscvでpboを確認
transaction costsを導入すべきか考える、また最適化する関数の返り値がeffective_marginでは、過学習するからリスクを考慮した指標を使用するべきで、sharp_ratioか、最大ドローダウンなどを組み合わせた独自の関数を作るか考える→遺伝プログラミングで評価関数を自動で生成すれば良いのではないか


・各戦略が生成したリターンの統計的な性質に焦点を当てた論文

A Bayesian Approach to Measurement of Backtest Overfitting (2021年のものなのでまだcitationが少ない)
https://chatgpt.com/g/g-hxDOCBQrs-paper-interpreter-japanese/c/66e2115f-c26c-800e-ac38-9ebc1d24fa2e
指定した平均と標準偏差から複数の投資戦略のリターンを生成し、MCMCを使って戦略の平均と共分散をサンプリング。その後、その平均と共分散からout_sampleリターンを生成し、シャープレシオを計算。




・各戦略のパラメータを具体的に最適化することに焦点を当てた論文
    <GA関連>
Parameter Optimization for Trading Algorithms of Technical Agents
https://chatgpt.com/g/g-hxDOCBQrs-paper-interpreter-japanese/c/66e214f0-9a78-800e-a1cc-f45886fd52c0
BOとGAを使って累積リターンが最大となるようなRSIの下限値と上限値、ボリンジャーバンドの平均と標準偏差を推定
ロールフォワード法によるoverfit軽減

FOREX Trading Strategy Optimization (citationほぼ0)
https://chatgpt.com/g/g-hxDOCBQrs-paper-interpreter-japanese/c/66dc4040-d17c-800e-aada-7f882fe2e79c
GAを使って移動平均の次数、取引頻度のパラメータ、最小閾値を最適化
trainとtestを分けただけ



    <svm関連>
Combining Support Vector Machine with Genetic Algorithms to optimize investments in Forex markets with high leverage (citation77)
https://chatgpt.com/g/g-hxDOCBQrs-paper-interpreter-japanese/c/66de16a3-db5c-800e-8c3a-d8228ae1bd8b
svmにより、市場のトレンドを３つに判別し、各トレンドに対応するGAで別々に最適化、GAはハイパーミューテーション、ハイパーセレクションを実行
svmに対してkfold交差検証を実施、GAに対してはtrainとtestを分けただけ

Modeling, forecasting and trading the EUR exchange rates with hybrid rolling genetic algorithms-Support vector regression forecast combinations (citation132)
https://chatgpt.com/g/g-hxDOCBQrs-paper-interpreter-japanese/c/66df6ac1-189c-800e-ba55-fd18a8a7e128
svrによって過去の為替レートから１日先の予測値を算出、GAでsvrのハイパーパラメータを調整。svrの入力データは教師データ：ARMAモデルやNNによって得られる１日先の予測値、教師ラベル：実際の１日先の値、として学習。GAの評価関数は、年率リターン-10*RMSE-0.001*(サポートベクターの数/トレーニングサンプル数)
svrに含まれる正則化項Cによって過学習を抑えられる
※為替データをそのまま与えるとoverfitしてしまうが、例えば移動平均線の値を与えると、入力データが平均化されていることで、overfitしにくくなるのではないか



<その他>
Evaluating machine learning classification for financial trading: An empirical approach (citation200)
https://chatgpt.com/g/g-hxDOCBQrs-paper-interpreter-japanese/c/66e0bb4c-2f04-800e-981e-684f82061d9e
シンプルな機械学習モデル（OneR, C4.5, JRip, Logistic Model Tree, KStar, Naïve Bayes）を使用し、予測精度が50%程度だったが高い収益性を誇った。異なる市場でも安定した結果となった。シンプルなモデルのため計算コストが低いことを活かして定期的に再訓練ができる

Data selection to avoid overfitting for foreign exchange intraday trading with machine learning
https://www.perplexity.ai/search/data-selection-to-avoid-overfi-NQKC0.7bQuqe17n3LDPRdA
新しくパスロス指標(精度＊log(正規化されたinsampleリターン)/収益率)を提案、２つの学習目的（回帰と分類）、２つの取引戦略（１機関保有、切り替えまで保有）、４つの機械学習モデルを使用（NN、ランダムフォレスト、SVM/SVR、XGBoost）


・新しい手法
Avoiding Backtesting Overfitting by Covariance-Penalties: an empirical investigation of the ordinary and total least squares cases (citation12)
https://chatgpt.com/g/g-hxDOCBQrs-paper-interpreter-japanese/c/66da70eb-4eb0-800e-a45b-4825778a7845
共分散ペナルティ補正法によるoverfitの回避




・交差検証の応用
The Probability of Backtest Overfitting (citation132)
https://chatgpt.com/g/g-hxDOCBQrs-paper-interpreter-japanese/c/66dba0a1-bcec-800e-9da5-89196b3a70b5
cscv法によるPBOの計算によりoverfitを定量的に評価できる

effective_margin+{(sharp_ratio-1)-effective_margin*max_draw_down}*effective_margin


・kabu_backtestで通貨ペアの二カ国のいずれかの祝日に被っている日は決済できないので、それをposition closure processingに追加で実装せよ
また、二カ国両方とも祝日の場合はどうなるか確認せよ
→swap pointの受け渡しができないだけで、祝日はfxの取引は通常通り行えるので、修正不要

・kabu_swap.pyを、minkabuだけでなくoandaからもスワップポイントをスクレイピングできるようにしつつ、oandaのサイトには掲載がない2019年4月より前のデータに対しては比率を計算して、理論値を算出するように実装せよ。

kabu_compare_intrestrate_and_oandascraping.py内で、calculate_swap_averages関数を呼び出す際に指定されるcurrent_startとcurrent_endの範囲で、kabu_oanda_swapscraping.pyで生成されるcsvファイルがあるかを判定してしまってる。
範囲を修正せよ。→解決

その後、average_buy_swap、average_sell_swapがそれぞれ０と２になってしまう原因を追求せよ
→解決

2024-11-03
kabu_compare_intrestrate_and_oandascraping.pyでほぼ正しい結果が出たが、2021-12~2022-02にかけての平均スワップの値が飛んでしまっているので、計算エラーかを確認せよ。


2024-11-09
kabu_swap.pyの__init__内のif found_file以下が正常に動作するかをkabu_backtest.pyを走らせて確かめる(つまりwebsite="oanda",interval="M1",link=link)
→確認完了

kabu_backtest.pyのlong_onlyのcheck swap　以下を修正したので、動作確認をする（つまり、website="minkabu",interval="1d"）
→long_onlyのcheck swap以下にpos[8] += ...を追加し、check_min_max_effective_marginを追加したことで変わるのは、シャープレシオと最大ドローダウンだけなので、check totalの値と有効証拠金の値の一致不一致には関係ない
動作確認は完了

website="oanda"でlong_onlyの時、計算が合わないようなので、確認（つまりまずはwebsite="minkabu",strategy="long_only"で動作確認）
→website="minkabu"では合うことを確認、website="oanda"では計算が合わないことを確認

→おそらく原因は、スクレイピングで得たデータは日本の日付でのスワップデータなので、それを世界基準に直さないとスワップポイントの計算でずれが生まれるのではないか


oanda証券のスワップカレンダーに記載されているスワップポイントの単位を調べよ

2024-11-10
kabu_swap.pyの以下の部分を追加で実装せよ

        # データ取得の制限を確認
        if start_date < datetime(2019, 4, 1):
            print("2019年4月以前のデータはありません。")
            start_date = datetime(2019, 4, 1)

2024-11-12
2024-11-09での確認結果と異なり、websiteやpairの値に関わらず計算が合わない場合があることを確認
Nov 2, 9のコミットでは、Nov 10とは異なり、計算が一致
Nov 9、でEURGBP website=oandaの時のみ計算の不一致を確認（初期条件はinterval=1d,initial_funds=2000000, grid_start=0.84, grid_end=0.94, ordersize=3000, num_traps_options = 100, profit_width=100）この条件では強制ロスカットが作動するが、website=oandaの時のみ計算が合わない
→kabu_swap.pyのget_total_swap_pointsのif self.website==oanda以下のwhile current <= current_dateの部分で、イコールが不要でさらにopen_dateからcurrent_dateまでの営業日数分だけスワップポイントを取得して足し合わせる必要がある。よってwhile current < open_date+timedelta(days=rollover_days) とするのが適切。この修正により、初期条件は(start_date=2021-01-04 end_date=2021-04-01,interval=1d,initial_funds=100000, grid_start=0.86, grid_end=0.91, ordersize=3000, num_traps_options = 100, profit_width=100) この初期条件で強制ロスカットが作動するが計算が一致することを確認
→while current < open_date+timedelta(days=rollover_days)　ではスワップポイントが０になってしまうので不適

Nov 9の時点で、
    website=oandaでかつM1のデータの場合に、ロスカットする場合もそうでない場合も計算が一致することを確認せよ→次に記す初期条件で強制ロスカット時も計算が合うことを確認(pair="EURGBP=X" interval=M1 website=oanda start_date=2021-01-04 end_date=2021-02-01 initial_funds=100000 grid_start=0.86 grid_end=0.91 strategies=long_only order_sizes=10000 num_traps_options=100 profit_width=100)
    →website=oandaでかつM1のデータの場合に、ロスカットする場合は計算が一致することを確認（interval=1dでも確認）
    kabu_swap.pyのif self.website == oanda以下の、返り値の部分で、oanda証券のサイトにはロールオーバーを考慮したスワップポイントが記載されているため、サイトにデータのある2019/04以降のデータでは、返り値はこの値で良いが、2019/04以前のデータはないため、自分でスワップポイントを計算する際はrollover_daysをかけないとだめ
    get_data_rangeメソッドで、dateとcurrent_startが完全に一致しないとstart_collectingフラグがTrueにならないので、たとえばEURGBPの2021/01/01のデータはないので、current_startをその日にするとダメ、修正せよ


2024-11-14
get_holidays_from_pairメソッド内でholidays.CountryHolidaysで指定した国の祝日をdict型に収納し、__init__以下でself.each_holidaysに保有させているが、祝日が日本語になってしまうため、multiprocessingによるpickle化ができない。よって、CountryHoliday().keys()のみをholidays_dictに保有させることで、祝日の名前を除外して日付のみを保有でき問題が解決する

2024-11-16
改めてkabu_swap.pyのget_total_swap_points内のwhile文を修正し、interval="1d"の時はwebsite="oanda"で計算が一致することを確認
→interval="M1"でロスカットが起こる場合(pair="EURGBP=X" interval=M1 website=oanda start_date=2021-01-04 end_date=2021-04-01 initial_funds=100000 grid_start=0.86 grid_end=0.91 strategies=long_only order_sizes=10000 num_traps_options=100 profit_width=100)に計算が一致するか確認中
 またロスカットが起きない場合も確認(pair="EURGBP=X" interval=M1 website=oanda start_date=2021-01-04 end_date=2021-02-01 initial_funds=10000000 grid_start=0.86 grid_end=0.91 strategies=long_only order_sizes=1000 num_traps_options=100 profit_width=100)

 website="oanda"の時は日付が日本になっているので、現地時間に直す必要がある

 2024-11-17
 kabu_backtest.pyで次の初期条件で計算の不一致を確認(pair: "AUDNZD=X", interval: 1d, website:minkabu, start_date:2019-11-01 00:00:00, end_date:2019-11-30 00:00:00, initial_funds:100000000, grid_start:1.02, grid_end:1.14, strategies:['long_only'], entry_intervals:[0], total_thresholds:[10000], order_sizes:[1000],num_trap_options:[100], profit_widths:[0.01], densities:[10])

 2024-11-19
 kabu_backtest.pyで上記の初期条件でinitial_fund=100000にすると計算エラーが発生することを確認
 →check swapをコメントアウトすると計算が一致することからスワップポイントの計算が原因であることがわかった
 →結局は、swapではなく、なぜかlong_onlyの時だけfor i in range(len(data))の次の、if margin_maintenance_flagの部分が、if margin_maintenance_flag or order_capacity_flag:になっていた。
  これだと、order_marginが０以下になったときに、ここでbreakしてしまうことで為替の変動に伴って発生する、すでに保有しているポジションの価格変動やスワップポイントの変動もしないままになるので、結果が合わなくなる

以上を踏まえて以前試した、計算結果が一致しない条件で再度確認(EURGBP=X, interval: M1, website:oanda, start_date:2021-01-04 00:00:00, end_date:2021-04-01 00:00:00, initial_funds:100000, grid_start:0.86, grid_end:0.91, strategies:['long_only'], entry_intervals:[0], total_thresholds:[1000], order_sizes:[10000],num_trap_options:[100], profit_widths:[100], densities:[10])

2024-11-21
上記の条件で確認したところ、不一致が確認された。なお2021-01-04 17:55:00 でロスカットされる。
試しに、check swapの部分をコメントアウトし、最後のswap_valueの計算を0としたところ、ロスカットが実行されていても一致
→ロスカットが実行された場合の、最後のswap_valueの計算が間違っているのではないか。

あとは、for i in range(len(data))とあり、dataの量が非常に多いと計算が重くなってしまう
→バッチ処理はどうか

そもそも、2024-11-19の最後に記した初期条件では、2021-01-04から始まり、2021-01-04 17:55:00でロスカットが執行されるが、website==oandaの時には、rollover_daysが0であるにも関わらず、スワップポイントが付与されてしまう仕様になっていたので、
if rollover_days== 0 と if rollover_days >= 1を追加して、0の時はそもそも計算などせずに0を返すようにkabu_swap.pyを修正した
しかし、その修正前に起きた計算の不一致の本質的な解決にはおそらくなっていない。つまり、特定の条件下でのみ計算の不一致が生じる問題の解決にはなっていない。
→とりあえず、修正したkabu_swap.pyで2024-11-19の最期に記した初期条件で、計算が一致するか確認

2024-11-23
kabu_swap.pyで、ロールオーバーの計算はadd_business_daysメソッドにより、ニューヨーク時間に直してから計算してるが、get_total_swap_pointsでwebsite=oandaの時に、self.swap_points_dictからスワップポイントのデータを取得する際に元となっているoanda証券のサイトでは、日付が日本になっているため、齟齬が生じる

2024-11-28
kabu_swap.pyをtest_get_holidays.pyに基づいて大幅に修正したが、正常に動作しないのでデバッグせよ

2024-11-30
kabu_swap.pyで、self.business_holidaysを作る際に、祝日を１年単位で取得した後に、それに含まれない時間帯をbusiness_daysとしているが、rolloverを計算する際に２営業日後の情報が必要
なので、12/31など年末ギリギリのデータが来たときに、その２営業日後が正しく計算できない可能性があるので、修正せよ

2024-12-1
ロスカットが実行される場合にswap_valueが正しく計算されない模様。値が0になってしまうので、おそらくswap_value計算時のget_total_swap_pointsメソッド周りでエラーがあると思われる

2024-12-3
    kabu_swap.pyのget_total_swap_pointsメソッドで、ロールオーバーを計算する前に、open_dateとcurrent_dateを、pairで指定される二カ国の現地時間でのNYクローズと比較することで、それを跨いでいない場合はそもそもロールオーバーは０に決まっているので計算する必要がない、という条件分岐を追加せよ
    →crossover_ny_closeメソッドをSwapCalculatorに追加した。
    https://www.oanda.jp/course/ty3/swap が見れなくなっているので、ny4に移行したほうがいいかも。さらに２つの違いの詳細を把握せよ
    →oanda証券のミスだったので、現在は復旧したためとりあえず問題なし。
    →pairの右側の単位でスワップポイントが表示されている(例えば、USDJPYならば円)ので、単位を合わせよ。

2024-12-5
    2019-4-1以前ではスワップカレンダーがないので、ScrapeFromOanda内で、計算するメソッドを定義し、その関数をSwapCalculatorのinitのところでwebsite=="theory"で動作するようにもせよ


2024-12-7
    kabu_compare_bis_intrestrate_and_oandascraping.py で累積平均や、移動平均の部分でもtheoryを普通の平均で計算してしまっているので、修正
    →このままで問題なし

2024-12-10
    scrape_from_oandaの手前で、found_fileの名称を決めているが、例えばend_date = 2024-10-31の時に、file名が2024-10-30のようにその1日前であっても、最初からscrapingしてしまうので、近い日付があればscrapeするのはその続きからになるように修正せよ
    また、kabu_oanda_swapscrapingのscrape_from_oandaと、kabu_swap.py内のScrapeFromOanda内のscrape_from_oandaメソッドを統一した方が良いのでは？

2024-12-12
    kabu_library.py のget_swap_points_dictメソッドのmissing_rangesに2019-4-1以前の範囲が指定された場合、その前段階ですでにファイルにある範囲のデータをダウンロードしているにも関わらず、scrape_from_oanda関数内でstart_date=2019-4-1,end_date=datetime.now(jst)としてしまうので、またこの範囲でスクレイピングが実行されてしまう。
    →get_swap_points_dictの最初で2019-4-1以前であれば、start_date=2019-4-1,end_date=datetime.now()とすることで、あらかじめ理論値計算に必要な、実際の値を可能な限りスクレイピングすることで解決

2024-12-14
    kabu_swap.pyで2019-4-1以前の場合にswap_points_dictを獲得すると、2019-3-30が土曜日にも関わらず、スワップポイントの値が０でない状態になる。
    おそらくkabu_compare_bis_intrestrate_and_oandascraping.pyのcalculate_theory_swap内の辞書output_dataを作成する際に時差の関係で、日付がずれてしまい、本来金曜日の値のはずが土曜日30日のスワップポイントとして表示されていると思われる
    →kabu_swap.pyのrollover_daysの計算を修正することで、平日のみを考慮して解決
    しかし、その部分の計算が非常に遅いので、要修正

    また、kabu_library.pyのget_data_range関数が、current_startやcurrent_endに休日を指定してしまうと、データがないため適切に範囲指定できない
    →current_start,current_endに最も近い日付にずらすようなアルゴリズムを追加実装せよ

2024-12-15
    前日の課題２つ（rollover_daysの計算、get_data_range)が未解決
    →1つ目はkabu_swap.pyを過去に戻って逐一営業日判定する方法の方が早いかも。比較せよ。

2024-12-17
    結局rollover_daysをwebsite ==oandaの時は計算しないことで、大幅な時間短縮には成功した。
    しかし、計算の不一致が発生し、kabu_swap.pyを遡っても原因不明
    →check swap 以下でget_total_swap_pointsでスワップポイントを計算する際に、pos[6]をopen_dateとして使用しており、crossover_by_ny_closeメソッド使用前は必ずこのcheck swap以下がadd_swapが０でも実行はされたので、pos[6]が毎回更新されていたが、crossover_by_ny_closeによってpos[6]の値の更新が不規則になり、得られるスワップポイントが検算結果と一致しない
     よってcrossover_by_ny_closeをコメントアウトすると計算が一致
    また、rollover_daysが非常に遅いので、要修正
    →trading_days_set = set(trading_days)が遅い原因

    今は、営業日を最初にintervalに応じてdictを作ってから実行しているが、start_dateとend_dateの期間が長いほど、営業日をinterval=M1で作るのに負荷がかかるから、前のプログラムのようにその都度休日と祝日でないかどうか調べてtimedelta(days=1)を足していく方法の方が計算が早いのではないか。

2024-12-19
    →結局self.business_daysではなくself.each_holidaysとする方が時間短縮になるので変更した
    2019年4月1日以前のスワップの理論値計算で移動平均を計算すると空になるので、修正せよ

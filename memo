kabu_montecarlo.pyが終わったら、kabu_backtest.pyを、cumulativeなreturnをtxtfileに保存するように修正して、再度kabu_montecarlo.pyを実行せよ
svmとGAの論文を読んで、完全に再現
svmとGAの論文で使われている、動的なGAについて、ハイパーパラメータをどう決めるか、その動的な手法が高精度なのはどのような原因が考えられるか解読する
svmとGAの論文以外にcitationの多い、overfitしていない先行研究を探す→Modeling, forecasting and trading the EUR exchange rates with hybrid rolling genetic algorithms-Support vector regression forecast combinations（citation132）
kabu_montecarlo.pyはパラメータを全て一様分布から生成しているが、これも先行研究を探す
covariance penalitesの論文にある、CV以外の先行研究となった手法を調べる
cpcvを日足より短い”大量の”データを使って再度試す
うまくいきそうなら、その結果に対してcscvでpboを確認
transaction costsを導入すべきか考える、また最適化する関数の返り値がeffective_marginでは、過学習するからリスクを考慮した指標を使用するべきで、sharp_ratioか、最大ドローダウンなどを組み合わせた独自の関数を作るか考える→遺伝プログラミングで評価関数を自動で生成すれば良いのではないか


・各戦略が生成したリターンの統計的な性質に焦点を当てた論文

A Bayesian Approach to Measurement of Backtest Overfitting (2021年のものなのでまだcitationが少ない)
https://chatgpt.com/g/g-hxDOCBQrs-paper-interpreter-japanese/c/66e2115f-c26c-800e-ac38-9ebc1d24fa2e
指定した平均と標準偏差から複数の投資戦略のリターンを生成し、MCMCを使って戦略の平均と共分散をサンプリング。その後、その平均と共分散からout_sampleリターンを生成し、シャープレシオを計算。




・各戦略のパラメータを具体的に最適化することに焦点を当てた論文
    <GA関連>
Parameter Optimization for Trading Algorithms of Technical Agents
https://chatgpt.com/g/g-hxDOCBQrs-paper-interpreter-japanese/c/66e214f0-9a78-800e-a1cc-f45886fd52c0
BOとGAを使って累積リターンが最大となるようなRSIの下限値と上限値、ボリンジャーバンドの平均と標準偏差を推定
ロールフォワード法によるoverfit軽減

FOREX Trading Strategy Optimization (citationほぼ0)
https://chatgpt.com/g/g-hxDOCBQrs-paper-interpreter-japanese/c/66dc4040-d17c-800e-aada-7f882fe2e79c
GAを使って移動平均の次数、取引頻度のパラメータ、最小閾値を最適化
trainとtestを分けただけ



    <svm関連>
Combining Support Vector Machine with Genetic Algorithms to optimize investments in Forex markets with high leverage (citation77)
https://chatgpt.com/g/g-hxDOCBQrs-paper-interpreter-japanese/c/66de16a3-db5c-800e-8c3a-d8228ae1bd8b
svmにより、市場のトレンドを３つに判別し、各トレンドに対応するGAで別々に最適化、GAはハイパーミューテーション、ハイパーセレクションを実行
svmに対してkfold交差検証を実施、GAに対してはtrainとtestを分けただけ

Modeling, forecasting and trading the EUR exchange rates with hybrid rolling genetic algorithms-Support vector regression forecast combinations (citation132)
https://chatgpt.com/g/g-hxDOCBQrs-paper-interpreter-japanese/c/66df6ac1-189c-800e-ba55-fd18a8a7e128
svrによって過去の為替レートから１日先の予測値を算出、GAでsvrのハイパーパラメータを調整。svrの入力データは教師データ：ARMAモデルやNNによって得られる１日先の予測値、教師ラベル：実際の１日先の値、として学習。GAの評価関数は、年率リターン-10*RMSE-0.001*(サポートベクターの数/トレーニングサンプル数)
svrに含まれる正則化項Cによって過学習を抑えられる
※為替データをそのまま与えるとoverfitしてしまうが、例えば移動平均線の値を与えると、入力データが平均化されていることで、overfitしにくくなるのではないか



<その他>
Evaluating machine learning classification for financial trading: An empirical approach (citation200)
https://chatgpt.com/g/g-hxDOCBQrs-paper-interpreter-japanese/c/66e0bb4c-2f04-800e-981e-684f82061d9e
シンプルな機械学習モデル（OneR, C4.5, JRip, Logistic Model Tree, KStar, Naïve Bayes）を使用し、予測精度が50%程度だったが高い収益性を誇った。異なる市場でも安定した結果となった。シンプルなモデルのため計算コストが低いことを活かして定期的に再訓練ができる

Data selection to avoid overfitting for foreign exchange intraday trading with machine learning
https://www.perplexity.ai/search/data-selection-to-avoid-overfi-NQKC0.7bQuqe17n3LDPRdA
新しくパスロス指標(精度＊log(正規化されたinsampleリターン)/収益率)を提案、２つの学習目的（回帰と分類）、２つの取引戦略（１機関保有、切り替えまで保有）、４つの機械学習モデルを使用（NN、ランダムフォレスト、SVM/SVR、XGBoost）


・新しい手法
Avoiding Backtesting Overfitting by Covariance-Penalties: an empirical investigation of the ordinary and total least squares cases (citation12)
https://chatgpt.com/g/g-hxDOCBQrs-paper-interpreter-japanese/c/66da70eb-4eb0-800e-a45b-4825778a7845
共分散ペナルティ補正法によるoverfitの回避




・交差検証の応用
The Probability of Backtest Overfitting (citation132)
https://chatgpt.com/g/g-hxDOCBQrs-paper-interpreter-japanese/c/66dba0a1-bcec-800e-9da5-89196b3a70b5
cscv法によるPBOの計算によりoverfitを定量的に評価できる

effective_margin+{(sharp_ratio-1)-effective_margin*max_draw_down}*effective_margin


・kabu_backtestで通貨ペアの二カ国のいずれかの祝日に被っている日は決済できないので、それをposition closure processingに追加で実装せよ
また、二カ国両方とも祝日の場合はどうなるか確認せよ
→swap pointの受け渡しができないだけで、祝日はfxの取引は通常通り行えるので、修正不要

・kabu_swap.pyを、minkabuだけでなくoandaからもスワップポイントをスクレイピングできるようにしつつ、oandaのサイトには掲載がない2019年4月より前のデータに対しては比率を計算して、理論値を算出するように実装せよ。

kabu_compare_intrestrate_and_oandascraping.py内で、calculate_swap_averages関数を呼び出す際に指定されるcurrent_startとcurrent_endの範囲で、kabu_oanda_swapscraping.pyで生成されるcsvファイルがあるかを判定してしまってる。
範囲を修正せよ。→解決

その後、average_buy_swap、average_sell_swapがそれぞれ０と２になってしまう原因を追求せよ
→解決

2024-11-03
kabu_compare_intrestrate_and_oandascraping.pyでほぼ正しい結果が出たが、2021-12~2022-02にかけての平均スワップの値が飛んでしまっているので、計算エラーかを確認せよ。


2024-11-09
kabu_swap.pyの__init__内のif found_file以下が正常に動作するかをkabu_backtest.pyを走らせて確かめる(つまりwebsite="oanda",interval="M1",link=link)
→確認完了

kabu_backtest.pyのlong_onlyのcheck swap　以下を修正したので、動作確認をする（つまり、website="minkabu",interval="1d"）
→long_onlyのcheck swap以下にpos[8] += ...を追加し、check_min_max_effective_marginを追加したことで変わるのは、シャープレシオと最大ドローダウンだけなので、check totalの値と有効証拠金の値の一致不一致には関係ない
動作確認は完了

website="oanda"でlong_onlyの時、計算が合わないようなので、確認（つまりまずはwebsite="minkabu",strategy="long_only"で動作確認）
→website="minkabu"では合うことを確認、website="oanda"では計算が合わないことを確認

→おそらく原因は、スクレイピングで得たデータは日本の日付でのスワップデータなので、それを世界基準に直さないとスワップポイントの計算でずれが生まれるのではないか


oanda証券のスワップカレンダーに記載されているスワップポイントの単位を調べよ

2024-11-10
kabu_swap.pyの以下の部分を追加で実装せよ

        # データ取得の制限を確認
        if start_date < datetime(2019, 4, 1):
            print("2019年4月以前のデータはありません。")
            start_date = datetime(2019, 4, 1)

2024-11-12
2024-11-09での確認結果と異なり、websiteやpairの値に関わらず計算が合わない場合があることを確認
Nov 2, 9のコミットでは、Nov 10とは異なり、計算が一致
Nov 9、でEURGBP website=oandaの時のみ計算の不一致を確認（初期条件はinterval=1d,initial_funds=2000000, grid_start=0.84, grid_end=0.94, ordersize=3000, num_traps_options = 100, profit_width=100）この条件では強制ロスカットが作動するが、website=oandaの時のみ計算が合わない
→kabu_swap.pyのget_total_swap_pointsのif self.website==oanda以下のwhile current <= current_dateの部分で、イコールが不要でさらにopen_dateからcurrent_dateまでの営業日数分だけスワップポイントを取得して足し合わせる必要がある。よってwhile current < open_date+timedelta(days=rollover_days) とするのが適切。この修正により、初期条件は(start_date=2021-01-04 end_date=2021-04-01,interval=1d,initial_funds=100000, grid_start=0.86, grid_end=0.91, ordersize=3000, num_traps_options = 100, profit_width=100) この初期条件で強制ロスカットが作動するが計算が一致することを確認
→while current < open_date+timedelta(days=rollover_days)　ではスワップポイントが０になってしまうので不適

Nov 9の時点で、
    website=oandaでかつM1のデータの場合に、ロスカットする場合もそうでない場合も計算が一致することを確認せよ→次に記す初期条件で強制ロスカット時も計算が合うことを確認(pair="EURGBP=X" interval=M1 website=oanda start_date=2021-01-04 end_date=2021-02-01 initial_funds=100000 grid_start=0.86 grid_end=0.91 strategies=long_only order_sizes=10000 num_traps_options=100 profit_width=100)
    →website=oandaでかつM1のデータの場合に、ロスカットする場合は計算が一致することを確認（interval=1dでも確認）
    kabu_swap.pyのif self.website == oanda以下の、返り値の部分で、oanda証券のサイトにはロールオーバーを考慮したスワップポイントが記載されているため、サイトにデータのある2019/04以降のデータでは、返り値はこの値で良いが、2019/04以前のデータはないため、自分でスワップポイントを計算する際はrollover_daysをかけないとだめ
    get_data_rangeメソッドで、dateとcurrent_startが完全に一致しないとstart_collectingフラグがTrueにならないので、たとえばEURGBPの2021/01/01のデータはないので、current_startをその日にするとダメ、修正せよ


2024-11-14
get_holidays_from_pairメソッド内でholidays.CountryHolidaysで指定した国の祝日をdict型に収納し、__init__以下でself.each_holidaysに保有させているが、祝日が日本語になってしまうため、multiprocessingによるpickle化ができない。よって、CountryHoliday().keys()のみをholidays_dictに保有させることで、祝日の名前を除外して日付のみを保有でき問題が解決する

2024-11-16
改めてkabu_swap.pyのget_total_swap_points内のwhile文を修正し、interval="1d"の時はwebsite="oanda"で計算が一致することを確認
→interval="M1"でロスカットが起こる場合(pair="EURGBP=X" interval=M1 website=oanda start_date=2021-01-04 end_date=2021-04-01 initial_funds=100000 grid_start=0.86 grid_end=0.91 strategies=long_only order_sizes=10000 num_traps_options=100 profit_width=100)に計算が一致するか確認中
 またロスカットが起きない場合も確認(pair="EURGBP=X" interval=M1 website=oanda start_date=2021-01-04 end_date=2021-02-01 initial_funds=10000000 grid_start=0.86 grid_end=0.91 strategies=long_only order_sizes=1000 num_traps_options=100 profit_width=100)

 website="oanda"の時は日付が日本になっているので、現地時間に直す必要がある

 2024-11-17
 kabu_backtest.pyで次の初期条件で計算の不一致を確認(pair: "AUDNZD=X", interval: 1d, website:minkabu, start_date:2019-11-01 00:00:00, end_date:2019-11-30 00:00:00, initial_funds:100000000, grid_start:1.02, grid_end:1.14, strategies:['long_only'], entry_intervals:[0], total_thresholds:[10000], order_sizes:[1000],num_trap_options:[100], profit_widths:[0.01], densities:[10])